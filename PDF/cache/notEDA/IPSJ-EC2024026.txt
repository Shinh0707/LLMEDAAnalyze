「エンタテインメントコンピューティングシンポジウム（EC2024）」2024 年 9 月
# 彩色済み参考画像から生成される領域情報を用いたアニメ線画の 自動彩色手法
## 南谷大輔 [†1] 米澤弘毅 [†2]

近年、アニメやマンガを代表とする日本のサブカルチャーは世界中で人気が高まっており、様々な媒体で放送されて
いる。アニメ制作における彩色の工程は、重要であると同時に多くの労力を必要とする工程でもある。本論文では、
彩色済みアニメ画像を用いて線画を自動で彩色する手法について取り扱い、彩色された画像の確認と検証を行った。
線画の自動彩色手法を開発することにより、我々は彩色にかかる労力を減少させることを目標にしている。提案手法
は、線画に存在する領域が参考画像のどの領域と対応するのかを推測することにより彩色を行う。
# **Colorization of anime line art using region information obtained ** **from reference images **
## Daisuke Nanya [†1] Kouki Yonezawa [†2]

### 1. はじめに

アニメの制作には多くの時間と人的資源を必要とし、多

数の工程を経由することにより制作される。工程には、脚

本の制作や絵コンテの制作など作品の展開を導く工程もあ

れば、原画の制作やコンピュータグラフィックスを用いた

キャラクターの動きの構築など実際に放送される画像を制

作する工程もある。近年のコンピュータ技術の発達によっ

て、アニメの制作にもコンピュータグラフィックスやモー

ションキャプチャの技術を導入するなどコンピュータを用

いた工程も増えてきた。しかし、全ての工程がコンピュー

タに置き換わってはおらず、原画の作成など手作業の工程

も多数存在する。

アニメの彩色についてアニメ制作会社である株式会社ト

リガー[1]へインタビューを行った。現在、彩色（専門用語

では仕上げという）を担当する部署では若年層が少なくな

りつつあり、担当者の高齢化という課題があることがわか

った。そのため、自動彩色ツールによる仕上げ作業の効率

化は非常に有用なものであると確認できた。また、現在日

本のアニメに適応できるような自動彩色のツールは業界で

は使われていないことも確認できた。

続いて仕上げに至るまでの工程について説明する。最初

に手作業で紙に絵を描き原画を制作する。原画には複数の

色の線を描く。黒色は仕上げ後も残る線（専門用語では実

線という）、赤色は基準となる色（専門用語ではノーマルと

いう）よりも明るい（専門用語ではハイライトという）領

域、青色はノーマルよりも暗い（専門用語では影という）

領域を表している。実線は仕上げ後も残るが、ハイライト

の線や影の線は仕上げ後には残らない。作品やカットによ

- 1 名城大学 理工学研究科
Meijo University

- 2 名城大学 情報工学部
Meijo University

ⓒ2024 Information Processing Society of Japan


っては複数の影が存在する場合もある。この場合、明るい

影から暗い影に向かって一号影、二号影というように影の

前に付く数字が増えていく。

完成した原画から動画を作成する。動画の制作は原画を

スキャナーでデジタルデータに変換し、原画の線を清書す

る（クリーンアップ）作業である。クリーンアップでは原

画を参考に実線、ハイライトの線、影の線を液晶タブレッ

ト上で描き、二値画像を制作する。この際、仕上げの工程

でベタ塗り機能を利用するため、線が途切れることなくあ

らゆる領域が閉領域になるよう注意しながら作業を行う。

図 1 に原画と動画の例を示す。

図 1 原画（左）と動画（右）の例（共に[2]より引用）

仕上げは動画の制作の後で行われ、ペイントツールを用

いて行い、アニメの制作現場においては主に RETAS

STUDIO[3]というペイントツールが利用されている。仕上

げでは制作された動画を参考に領域ごとにベタ塗りを行う。

使用する色はあらかじめ指定されており、キャラクターご

とに昼のシーン、夜のシーンなどカットの状況に合わせて

ハイライト、ノーマル、一号影、二号影というように複数

の色が指定されていることが多い。仕上げは動画に描かれ

ている領域の数にもよるが、一枚当たり 30 分ほどかかる

こともある。図 2 に仕上げまでの工程の概要図を示す。

167


-----

図 2 仕上げまでの工程の概要図

本研究では仕上げの工程にかかる労力の削減を目的とす

る。提案手法ではアニメ画像が多数の領域から構成されて

いることに着目した。線画に存在する領域が参考画像のど

の領域と対応するのかを推測し、対応すると推測できる領

域の色で線画を彩色するシステムを構築した。トリガー社

とのインタビューから、正解率は 90 パーセント以上かつ

動画一枚にかかる仕上げの時間は 10 秒以内に抑えること

を目標にしているが、提案手法では面積ベースの計算で

90%を超える正解率が得られた。
### 2. 関連研究

画像をカラー化する手法は実画像を対象とした研究が多

数で、手描きの絵を対象とした研究は多くない。その中で

も手描きの絵を対象とし、彩色済み参考画像を用いて絵を

カラー化する研究はイラスト調の手法が多く、アニメを対

象とした手法はほとんどない。ここではマンガとイラスト

のカラー化に関する手法について紹介する。

**2.1** グラフマッチングを用いた手法

佐藤ら[4]はマンガ調の画像をカラー化することを目的と

して、マンガの絵が多数の領域で構成されている点に着目

し、領域同士のノードを推測することにより領域の対応付

けを行う手法を提案している。このシステムへは彩色済み

参考画像と線画を入力し、参考画像に含まれる領域同士の

ノードを用いて線画をカラー化する。具体的には、参考画

像と線画のそれぞれにおいて領域同士のノードを作成する。

作成された線画のノードが参考画像のノードと対応するの

かを推測することにより、領域同士の対応付けを行い、参

考画像の色で彩色する。

この手法のメリットとして、線画は参考画像に含まれる

色のみで彩色される点が挙げられる。また、機械学習を利

用しないため、著作権に配慮した大量の学習データを用意

ⓒ2024 Information Processing Society of Japan


する必要がない。

**2.2** ニューラルネットワークを用いた手法

Cao ら[5]はイラスト調の画像の線画を入力として、機械

学習の手法の一つである Generative Adversarial Networks（敵

対的生成ネットワーク）を用いて彩色する手法を提案して

いる。機械学習を用いた手法ではニューラルネットワーク

を利用し、線画を畳み込むことでその特徴量を利用したも

のが多くを占める。この手法では特徴量を抽出する際に近

年様々な研究で利用されている Attention 機構を導入する

ことで精度向上を図っている。

この手法のメリットとして、参考画像と線画の構図が異

なっても彩色できる点、参考画像を入れ替えることで様々

な色使いを基にした彩色ができる点が挙げられる。これは

大量の画像を用いてネットワークを学習することにより、

構図の異なる場合においても対応できるようになっている。

しかしながら、生成画像がアニメに向いていると保証でき

ないデメリットがある。また、著作権に配慮した学習デー

タを大量に用意する必要がある点、GPU の利用が必要であ

る点、学習に時間がかかる点などのデメリットが挙げられ

る。
### 3. 提案手法

提案手法は関連研究と異なる点がいくつかある。まず、

グラフマッチングを用いた手法とは異なり領域同士のノー

ドの推測ではなく、領域を直接推測する点である。次に、

ニューラルネットワークを用いて直接の画像生成は行わな

い点である。そのため、参考画像に含まれない色が出力さ

れることはなく、アニメの画像に向いた一つの領域で使用

される色は一色のみとなる画像を出力できる。最後に、機

械学習を行わない点である。

提案手法のメリットは機械学習を使用しないため、機械

学習を利用する際に度々問題になる学習データの著作権に

関する問題は発生しない。また、画像の出力に長時間かか

ることはない。

提案手法では動画は多数の領域で構成されており、一つ

の領域で使われる色は一色のみであることに着目した。画

像の色を直接予測するのではなく、動画の領域が彩色済み

参考画像のどの領域と対応するのかを予測する手法となっ

ている。そのため、参考画像に含まれる色のみで彩色する

ため、参考画像に存在しない色で彩色されることはない。

**3.1** システムの概要

システムは彩色したい動画と彩色済みの参考画像を入力

として受け取り、彩色された動画を出力する。図 3 に構築

したシステムの概要を示す。

168


-----

システムの目標は彩色済み参考画像と同一カット内の動

画の画像を彩色することである。システムでは動画と参考

画像における領域の対応付けを推測することにより動画を

彩色する。まずは動画と参考画像から領域情報を抽出する。

その後、線画に存在する領域がどの参考画像の領域と対応

しているのかを推測し、その結果を基に参考画像の領域の

色で線画の彩色を行う。ただし、このままでは境界画素が

残ったまま画像が出力されてしまうので、境界画素の除去

を行う。

参考画像 動画

領域情報抽出 領域情報抽出


線画の場合は 200、参考画像の場合は[128, 128, 128]の画素

値で選択画素値を設定し説明を行う。

**3.2.2** 領域探索

画像を左上から右へ順番に画素の確認を行い、抜き出す

べき領域かどうかの探索を行う。動画の場合は画素が背景

画素であれば、参考画像の場合は画素が実線画素以外であ

れば、領域抜き出しの工程へ進む。そうでなければ確認し

た画素の右へ行きラスタ走査を画像全体で行う。

**3.2.3** 領域抜き出し

3.2.2 節で述べた抜き出すべき領域の存在する座標に選

択画素値で塗りつぶし処理を行い、領域を抜き出す。塗り

つぶす画素値は 3.2.1 で説明した画像中に存在しない画素

値で行う。図 4 に動画における領域選択の前と後の例を、

図 5 に参考画像における領域選択の前と後の例を示す。

図 4 動画における領域選択の前（左）と後（右）の例

図 5 参考画像における領域選択の前（左）と後（右）の

例

領域を選択した後に選択画素値となっている画素のみを

抜き出す。抜き出す領域を白色、抜き出さない領域を黒色

として領域を抜き出す。図 6 に動画における領域抜き出し

の前と後の例を、図 7 に参考画像における領域抜き出しの

前と後の例を示す。

図 6 動画における領域抜き出しの前（左）と後（右）の

例

169







図 3 構築したシステムの概要図

**3.2** 領域情報抽出

領域情報抽出の工程では画像の持つ領域の情報を抽出し

保存する。抽出する情報は動画と参考画像の場合で共通す

る情報もあれば異なる情報もある。共通する情報は領域の

ID、�座標、�座標、画素数、重心�座標、重心�座標、最小

�座標、最小�座標、最大�座標、最大�座標である。ID は領

域を識別するための番号である。参考画像の場合はこれら

に加えて、領域の R, G, B の画素値を保存する。領域の画素

値は彩色の工程でベタ塗りを行う際に利用する。

領域情報を抽出する手順は動画と参考画像のどちらも同

じである。最初に画像中に含まれない画素値を決める。そ

の後、対象領域を探索し、領域を抜き出す。そして領域情

報を取り出しデータとして保存し、対象領域を実線画素に

置き換える。この手続きを画像に含まれる全ての画素の探

索が終わるまで繰り返す。

**3.2.1** 選択画素値の決定

領域情報を抽出した後、領域を抜き出す際に抜き出すべ

き領域を一時的に置き換えるための画素値を決める。この

画素値を選択画素値ということにする。選択画素値は画像

に含まれない画素値で設定する。以降のサンプル画像では

ⓒ2024 Information Processing Society of Japan


-----

調べる際に利用する指標は領域の面積、重心座標、バウ

ンディングボックスの 4 隅の座標（左上座標、右上座標、

左下座標、右下座標）の 3 つである。図 9 に領域における

バウンディングボックスの 4 隅の座標について示す。これ

らの座標は最小�座標、最小�座標、最大�座標、最大�座標

から構成される。


図 7 参考画像における領域抜き出しの前（左）と後（右）

の例

**3.2.4** 領域情報の取り出し

3.2.3 節で述べた領域として抜き出された画像の情報を

取り出し保存する。取り出す情報は画像の中で白色となっ

ている画素の数、重心�座標、重心�座標、最小�座標、最小

�座標、最大�座標、最大�座標を取得する。図 8 に最小と

最大の座標の表し方を示す。





図 8 領域における最小と最大の座標

参考画像の場合はこれらに加えて選択された画素の色も

保存する。これらの情報は CSV ファイルで保存される。表

1 に領域情報を含んだファイルのイメージを示す。

|Col1|表 2 参考画像の領域情報の例|
|---|---|
|ID|面積 重心(, ) 最小(, ) 最大(, )|
|1 2 3|0.25 (0.2, 0.2) (0.1, 0.1) (0.6, 0.4) 0.05 (0.7, 0.4) (0.5, 0.3) (0.8, 0.6) 0.05 (0.6, 0.7) (0.3, 0.4) (0.8, 0.9)|







|表|表 1 領域情報を含んだファイルのイメージ|
|---|---|
|ID|面積 重心 重心 ・・・ |
|1 2 ・ ・ ・ 100|80000 400 10 ・・・ 0 1000 50 20 ・・・ 0 ・ ・ ・ ・ ・ ・ ・ ・ ・ ・ ・ ・ 4000 900 800 ・・・ 750|


**3.2.5** 対象領域を実線画素に置き換え

ここでは再び抽出した領域画素を実線画素に置き換える。

動画と参考画像どちらの場合でも実線画素に置き換える。

この処理を行うことで次の領域情報を保存する際にこれま

でに抜き出した領域情報の加味を防ぐ。

**3.3** 領域対応付け

領域対応付けの工程では 3.2 節の工程で得られた情報を

基に動画と参考画像における領域の対応付けを行う。対応

付けは動画に含まれる調べたい領域の情報を基に参考画像

に含められる全ての領域情報を調査することで、調べたい

領域が参考画像のどの領域に最も似ているのかを導き出す。

この処理を動画に含まれる調べたい領域の数だけ繰り返し、

動画に含まれる全ての領域を参考画像の領域と対応付ける。

ⓒ2024 Information Processing Society of Japan


図 9 バウンディングボックスの 4 隅の座標

動画と参考画像の画素数が異なることを考慮し、領域情

報を調べる前に値の調整を行う。具体的には、動画と参考

画像それぞれの領域における画素数、重心�座標、重心�座

標、最小�座標、最小�座標、最大�座標、最大�座標を 0 か

ら 1 で正規化する。

ここからの領域対応付けでは表 2 を参考画像の領域情

報、表 3 を線画における調査領域の情報として具体例を交

えて説明する。

表 3 線画における調査領域の情報の例

面積 重心( �, � ) 最小( �, � ) 最大( �, � )

0.2 (0.4, 0.3) (0.1, 0.2) (0.7, 0.6)

**3.3.1** 対応付けた領域の面積の算出

ここでは領域の面積を指標として、調べたい領域が参考

画像のどの領域の面積に近いのか調べる。具体的には、参

考画像に含まれる領域の面積から調べたい領域の面積の差

を取り、その差を絶対値に変換する。この処理を参考画像

に含まれる領域の数繰り返し、絶対値が最も小さい領域を

1 として小さい順に順位を付けていく。同じ値の場合は同

一順位を付ける。表 3 を調査領域の情報、表 2 を参考画像

の領域情報とする場合の面積を指標とした順位算出の例を

表 4 に示す。

表 4 面積を指標とした順位算出の例

170


-----

**3.3.2** 重心間の距離の計算

ここでは領域の重心間の距離を指標として、調べたい領

域が参考画像のどの領域に場所が近いのか調べる。重心位

置の算出には重心�座標、重心�座標を利用し、参考画像に

含まれる全ての領域と調べたい領域の重心の距離を算出す

る。重心の距離が最も小さい領域を 1 として小さい順に順

位を付けていく。順位のつけ方は 3.3.1 節と同じである。表

5 に表 3 を調査領域の情報、表 2 を参考画像の領域情報と

する場合の重心距離を指標とした順位算出の例を示す。

|Col1|表 5 重心距離を指標とした順位算出の例|
|---|---|
|ID|重心距離の二乗 順位|
|1 2 3|0.05=(0.04+0.01)=((0.2-0.4)^2+(0.2-0.3)^2) 1 0.10=(0.09+0.01)=((0.7-0.4)^2+(0.4-0.3)^2) 2 0.20=(0.04+0.16)=((0.6-0.4)^2+(0.7-0.3)^2) 3|



**3.3.3** バウンディングボックスの 4 隅の座標間の距離

ここでは領域のバウンディングボックスの 4 隅の座標間

の距離を指標として、調べたい領域が参考画像のどの領域

に場所が近いのか調べる。

4 隅の座標を利用することで、重心だけでは測ることので

きない縦長や横長の領域など領域の特徴を領域の推測に用

いることができる。調べたい領域と参考画像の領域におい

て 4 隅の座標同士の距離を算出する。これら 4 隅の座標間

の距離の合計が最も小さい領域を 1 として小さい順に順位

を付けていく。順位のつけ方は 3.3.1 節と同じである。表 6

に表 3 を調査領域の情報、表 2 を参考画像の領域情報と

する場合の重心距離を指標とした順位算出の例を示す。

表 6 4 隅の座標を指標とした順位算出の例

|ID|合計距離 順位|
|---|---|
|1 2 3|√0.01 + √0.02 + √0.05 + √0.05 1 √0.17 + √0.02 + √0.16 + √0.01 2 √0.08 + √0.05 + √0.13 + √0.10 3|



**3.3.4** 対応する領域の決定

ここでは算出された 3 つの順位を用いて調べたい領域が

参考画像のどの領域と最も似ているのかを決定する。決定

には算出された 3 つの順位の積が最も小さい参考画像の領

域を動画の領域に最も似ているとして対応付ける。表 7 に

算出された 3 つの順位を利用した累計順位算出の例を示す。

|表|7 3 つの順位を利用した累計順位算出の例|
|---|---|
|ID|順位 面積 重心 4 隅 累計|
|1 2 3|1 1 1 1 2 2 2 8 2 3 3 18|



表 7 では累積順位が最も小さくのなる領域は ID が 1 で

ⓒ2024 Information Processing Society of Japan


ある。そのため、表 3 の領域情報を持った領域は ID が 1

の領域と対応付けられる。

**3.4** 実線画素変換

実線変換の工程では動画に描かれている黒色の実線を色

指定で決められた色に変換する処理を行う。色指定で決め

られる実線の色はカラーであることが多いため、この工程

で線画はグレースケール画像からカラー画像に置き換える。

**3.5** 彩色

彩色の工程では 3.3「領域対応付け」で作成された情報を

基に動画の対象領域へベタ塗りを行う。

**3.6** 境界画素除去

境界画素除去の工程では色のベタ塗りに使用した境界画

素を除去し、その周囲の色に置き換える処理を行う。境界

画素があった画素には周囲 8 画素の中から最もよく使われ

る画素に置き換える。この時再び境界画素に置き換えられ

ないようにするため、境界画素を除いた画素から最もよく

使われる画素に置き換える。境界画素が画像の端にある場

合は周辺 8 画素は使用できないため、周囲 3 画素や周囲 5

画素を用いる。この処理は境界画素が画像中に存在しなく

なるまで繰り返す。

しかし、この手法では境界画素が複数にまたがる領域の

間に存在する性質上どの領域の色に置き換えるのが正解か

わからない。そのため、境界画素が望んだ領域の色となら

ない可能性もあるが、境界画素は塗りつぶす領域に比べて

そこまで大きくなく、問題にしないこととした。
### 4. 評価検証

システムの評価検証には実際にアニメとして制作された

「映画リトルウィッチアカデミア魔法仕掛けのパレード」

[6]のデータセット[7]を用いて行う。このデータセットには

脚本、絵コンテ、キャラクターデザイン、原画などアニメ

の制作に関する多数のデータから構成されている。この中

から彩色済み画像を使用して評価検証を行った。本来であ

れば、彩色前の動画を用いてシステムの評価検証を行うべ

きであるが、データセットに動画は含まれていなかった。

そのため、動画に相当する画像を彩色済み画像から生成す

ることで評価検証を行った。

**4.1** 彩色済み画像から動画の生成

ここでは彩色前の動画になるべく近づけられるよう図

10 のように変換を行い、彩色済み画像から動画を生成する。

画像に含まれる輪郭を目立たせることで線画を生成するツ

ールは画像編集ソフトなどで多数存在するが、ほとんどが

白色と黒色に変換するものであり、実線と領域の境界を区

171


-----

別して線画を生成するようなツールは見つからなかった。

そのため、アニメの動画に該当する画像を生成するツール

を自分たちで作成した。

図 10 動画へ変換前（左）と変換後（右）の画像

画像中の色について説明する。変換前の画像において、

白色は背景色、茶色は実線、緑色はカラー色 1、青色はカ

ラー色 2 を表す。変換後の画像において、白色は背景また

はベタ塗りさせる領域、灰色は彩色後には残らない色が変

わる境界画素、黒色は実線を表す。

評価検証における動画の生成では画素値を黒線が 0、灰

色が 128、白色が 255 とする。これは利用するデータセッ

トの中に画素値が[128, 128, 128]の画素値が含まれていな

いためである。また、境界画素はハイライトの線や影の線

を示すため、本来であれば青色や赤色の色を使用する。し

かし、利用するデータセットには動画が含まれておらず、

どのような色が利用されていたか分からないため、今回は

実線によらない領域の境界を全て灰色にすることとした。

本来とは異なる色で領域の境界を示すことになるが、提案

手法では境界画素の色は推論に用いていないため、結果に

影響を及ぼすことはない。

彩色済み画像から動画を生成するには実線となる画素値

の設定、実線の描画、境界画素の描画という三つの工程を

経由することで行う。彩色済み画像はカラー画像、変換後

の動画はグレースケール画像である。

しかし、画像の解像度を変更せずに彩色済み画像をその

まま線画化すると、図 11 の右側の青色の領域のように同

じ領域が分断されてしまうことがある。領域が分断されて

しまうと彩色の工程でベタ塗りを行う際に不都合が生じる

可能性があるため、意図しない領域の分断は回避する必要

がある。

図 11 解像度変更前の彩色済み画像（左）と線画（右）

そこで、同じ領域が分断されないようにするため、画像

における縦横の画素数をそれぞれ 2 倍にし、解像度を 4 倍

にしてから線画化を行う。図 12 のように解像度を 4 倍に

ⓒ2024 Information Processing Society of Japan


変更した後で線画を生成すると、同じ領域の画素が分断さ

れるてしまうことはなくなった。このような領域の分断は

領域の縦や横の画素数が極めて小さいときに発生する。

図 12 解像度変更後の彩色済み画像（左）と線画（右）

**4.1.1** 実線となる画素値の設定

実線となる画素値の設定では参考画像の実線の画素値を

設定する。これは色指定で画素値が決められているので、

その値で設定する。

**4.1.2** 実線の描画

実線の描画では彩色済み画像に含まれる実線のみを取り

出し、新しい画像に書き込む処理を行う。

具体的には、まず彩色済み画像と同じ画素数の白色のグ

レースケール画像を用意する。次に、4.1.1「実線となる画

素値の設定」で設定した画素値と彩色済み画像に含まれる

同じ画素値の場所に黒色の画素値をグレースケール画像に

書き込む。

**4.1.3** 境界画素の描画

境界画素の描画では実線ではない領域が変わる境界画素

に灰色を書き込む処理を行う。

具体的には、ある画素とその右隣の画素またはその下隣

の画素に差がみられる場合、4.1.2「実線の描画」で作成し

たグレースケール画像のある画素の場所に灰色の画素値を

書き込む。ただし、その差が実線との差の場合は書き込ま

ない。

しかし、このままでは図 13 の左側のように描画されて

しまいペイントの塗りつぶし機能で必要のない画素も灰色

として描画されてしまう。これは境界が斜めの場合に発生

する。図 13 の右側のように灰色の画素が必要最低限とな

るように境界画素を描画した後に余分な境界画素の除去を

行う。

図 13 境界画素描画の改良前（左）と改良後（右）の画像

余分な境界画素の除去は、調査画素、調査画素の左隣の

画素、調査画素の上隣の画素全てが灰色の場合に調査画素

を白色にする。加えて、調査画素、調査画素の右隣の画素、

172


-----

調査画素の上隣の画素全てが灰色の場合にある画素を白色

にする。これを画像中の灰色の画素全てで行う。

**4.2** 出力画像の評価検証

評価検証では 10 個の異なるカットを用いて 20 枚の出力

画像を生成した。いずれも動画は参考画像の 1 つ前と後ろ

のフレームであり、キャラクター全体が動いている画像で

ある。動画は彩色済み画像を 4.1.1「実線となる画素値の設

定」の方法で生成された画像を使用し、参考画像は彩色済

み画像をそのまま使用する。生成した 20 枚において正し

く領域を推測できた正解率は領域ベースで 72.66%、面積ベ

ースで 97.00%であった。その中からいくつか例を示す。

一つ目にキャラクターの顔が映っていないカットの彩色

結果を示す。図 14 にシステムへ入力する動画と参考画像

を、図 15 にシステムによる出力画像とその正解画像を示

す。ここでの動画は参考画像の 1 つ後ろのフレームである。

図 14 一つ目の評価で用いる線画（左）と参考画像（右）

図 15 図 14 を入力としたシステムによる出力画像（左）

とその正解画像（右）

図 15 の出力画像の正解率は領域ベースで 63.29%、面積

ベースで 99.05%である。出力画像は背景、服、手、杖など

面積の大きな領域では高い精度で領域を推定できているこ

とが確認できた。しかし、杖の中や杖の外に伸びる細長い

領域など面積の小さな領域で領域推定ミスが確認できた。

二つ目にキャラクターの全体が描かれているカットの彩

色結果を示す。図 16 にシステムへ入力する動画と参考画

像を、図 17 にシステムによる出力画像とその正解画像を

示す。ここでの動画は参考画像の 1 つ後ろのフレームであ

る。

図 16 二つ目の評価で用いる線画（左）と参考画像（右）

ⓒ2024 Information Processing Society of Japan


図 17 図 16 を入力としたシステムによる出力画像（左）

とその正解画像（右）

図 17 の出力画像の正解率は領域ベースで 77.33%、面積

ベースで 99.83%である。出力画像は背景や服など面積の大

きな領域では高い精度で領域を推定できていることが確認

できる。しかし、服の中や帽子の中にあるような小さな領

域、髪の領域など面積の小さな領域で領域推定ミスが確認

できた。

三つ目にキャラクターの全体が描かれているカットの彩

色結果を示す。

図 18 三つ目の評価で用いる線画（左）と参考画像（右）

図 19 図 18 を入力としたシステムによる出力画像（左）

とその正解画像（右）

図 19 の出力画像の正解率は領域ベースで 74.42%、面積

ベースで 99.22%である。出力画像は背景や顔など面積の大

きな領域では高い精度で領域を推定できていることが確認

できる。しかし、髪や服の中の小さな領域など面積の小さ

な領域で領域推定ミスが確認できた。

正解率は領域ベースよりも面積ベースの方が高いことか

ら、全体的に面積の大きな領域の方が正しく領域を推測さ

れやすいことが読み取れる。
### 5. おわりに

本研究では、アニメの彩色における彩色済み参考画像を

用いた線画の自動彩色手法を行うシステムの構築を行った。

また、実際にアニメとして制作されたデータセット[7]を

用いて評価検証を実施した。大きい領域の予測は高い精度

で彩色できるが、小さい領域の予測は精度が低く彩色の色

を間違えやすいと確認できた。そのため、アニメの仕上げ

の工程に提案手法を用いる場合、主に小さな領域の色を手

173


-----

作業で修正する作業が発生することになる。しかし、実行

時間は領域の推測は数秒で完了するものの、画像の領域情

報の抽出にかかるには 10 秒以上時間を要するため、実行

時間をより短くする必要がある。

今後は領域における形の類似度を導入することで、推測

の精度を向上させていくと同時に、彩色全体にかかる時間

を短くできるように手法の効率化を図っていきたい。

謝辞 本研究は株式会社トリガー様よりデータセット

を提供して頂きました。この場を借りて深く御礼申し上げ

ます。
#### 参考文献

[1] Trigger, Inc., TRIGGER official website, (2024).
https://www.st-trigger.co.jp/.

[2] CELSYS,Inc., trace function, RETAS STUDIO.Net (2020).
http://www.retasstudio.net/products/traceman/trace/.

[3] CELSYS, Inc., RETAS STUDIO.net, (2020).
http://www.retasstudio.net/.

[4] K. Sato, Y. Matsui, T. Yamasaki, K. Aizawa, Reference-based
manga colorization by graph correspondence using quadratic
programming, in: SIGGRAPH Asia 2014 Technical Briefs, Association
for Computing Machinery, 2014: pp. 1–4.
https://doi.org/10.1145/2669024.2669037.

[5] Y. Cao, H. Tian, P.Y. Mok, Attention-Aware Anime Line
Drawing Colorization, (2023).
https://doi.org/10.48550/arXiv.2212.10988.

[6] TRIGGER, Y. Yoshinari, GOOD SMILE COMPANY, “Little
Witch Academia: The Enchanted Parade” official website, (2015).
http://littlewitchacademia.jp/.

[7] National Institute of Informatics, Trigger dataset, IDR
Informatics Research Data Repository (2022).
https://www.nii.ac.jp/dsc/idr/trigger/.

ⓒ2024 Information Processing Society of Japan


174


-----

